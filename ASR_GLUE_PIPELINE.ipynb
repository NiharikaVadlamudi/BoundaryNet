{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NiharikaVadlamudi/BoundaryNet/blob/main/ASR_GLUE_PIPELINE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CfJ9Z4aWYTFY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "outputId": "dd81b3f9-7402-4af3-dd83-b273e3adbc6a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f21c4b903a3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    122\u001b[0m       'TBE_EPHEM_CREDS_ADDR'] if ephemeral else _os.environ['TBE_CREDS_ADDR']\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    125\u001b[0m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   request_id = send_request(\n\u001b[1;32m    170\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    100\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    101\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "# Load the Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vit_pytorch\n",
        "!pip install empatches"
      ],
      "metadata": {
        "id": "l87PgoGplc3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plantcv\n",
        "from plantcv import plantcv as pcv\n",
        "pcv.params.debug = None "
      ],
      "metadata": {
        "id": "3TX8jcayIQxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import cv2\n",
        "import os \n",
        "import pathlib\n",
        "import sys \n",
        "import numpy as np \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from vit_pytorch import ViT\n",
        "from einops import rearrange\n",
        "from empatches import EMPatches\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from vit_pytorch.vit import Transformer\n",
        "\n",
        "import math\n",
        "from shapely import geometry\n",
        "from skimage.graph import MCP_Connect\n",
        "from skimage.morphology import skeletonize\n",
        "from skimage.measure import label as skimage_label\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from scipy.signal import convolve2d\n",
        "from collections import defaultdict\n",
        "\n",
        "from scipy.spatial import distance\n",
        "import itertools\n",
        "import numba\n",
        "import itertools\n",
        "import glob\n",
        "import csv \n",
        "import json \n",
        "from collections import OrderedDict\n",
        "\n",
        "\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n"
      ],
      "metadata": {
        "id": "kX_486HSYsXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import json\n",
        "from itertools import combinations\n",
        "\n",
        "from shapely.affinity import scale\n",
        "from shapely.geometry import LineString, MultiPolygon, Polygon\n",
        "\n",
        "\n",
        "import json \n",
        "import os \n",
        "import cv2 \n",
        "import numpy as np \n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "K5UymyMTpVf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.4 ## binarization threshold after the model output\n",
        "SPLITSIZE =  256  ## your image will be divided into patches of 256x256 pixels\n",
        "setting = \"base\"  ## choose the desired model size [small, base or large], depending on the model you want to use\n",
        "patch_size = 8 ## choose your desired patch size [8 or 16], depending on the model you want to use\n",
        "image_size =  (SPLITSIZE,SPLITSIZE)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if setting == 'base':\n",
        "    encoder_layers = 6\n",
        "    encoder_heads = 8\n",
        "    encoder_dim = 768\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "IMAGE_PATH='/content/_data_ASR_Images_ASR-B02-S10_B02-S10-191.jpg'\n",
        "BMODEL = '/content/drive/MyDrive/researchTesting/best-model_8_2018base_256_8.pt'\n",
        "SMODEL = '/content/drive/MyDrive/researchTesting/try.pt'"
      ],
      "metadata": {
        "id": "_ArM3UqNYuoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class ScribbleNet(nn.Module):\n",
        "    \"\"\"\n",
        "    The autoencoder model to enhance images in an image to image translation fashion.\n",
        "    This code is built on top of the vit-pytorch code https://github.com/lucidrains/vit-pytorch.\n",
        "    Args:\n",
        "        encoder (model): the defined encoder, hete it is a ViT\n",
        "        decoder_dim (int): decoder dim (embedding size)\n",
        "        decoder_depth (int): number of decoder layers\n",
        "        decoder_heads (int): number of decoder heads\n",
        "        decoder_dim_head (int): decoder head dimension\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        encoder,\n",
        "        decoder_dim,\n",
        "        decoder_depth = 1,\n",
        "        decoder_heads = 8,\n",
        "        decoder_dim_head = 64\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # extract hyperparameters and functions from the ViT encoder.\n",
        "        self.encoder = encoder\n",
        "        num_patches, encoder_dim = encoder.pos_embedding.shape[-2:]\n",
        "        self.to_patch, self.patch_to_emb = encoder.to_patch_embedding[:2]\n",
        "        pixel_values_per_patch = self.patch_to_emb.weight.shape[-1]\n",
        "\n",
        "        # define your decoder here\n",
        "        self.enc_to_dec = nn.Linear(encoder_dim, decoder_dim) if encoder_dim != decoder_dim else nn.Identity()\n",
        "        self.mask_token = nn.Parameter(torch.randn(decoder_dim))\n",
        "        self.decoder = Transformer(dim = decoder_dim, depth = decoder_depth, heads = decoder_heads, dim_head = decoder_dim_head, mlp_dim = decoder_dim * 4)\n",
        "        self.decoder_pos_emb = nn.Embedding(num_patches, decoder_dim)\n",
        "        self.to_pixels = nn.Linear(decoder_dim, pixel_values_per_patch)\n",
        "\n",
        "    def forward(self, img, gt_img):\n",
        "        \n",
        "        # get patches and their number\n",
        "        patches = self.to_patch(img)\n",
        "        _, num_patches, *_ = patches.shape\n",
        "\n",
        "        # project pixel patches to tokens and add positions\n",
        "        tokens = self.patch_to_emb(patches)\n",
        "        tokens = tokens + self.encoder.pos_embedding[:, 1:(num_patches + 1)]\n",
        "\n",
        "        # encode tokens by the encoder\n",
        "        encoded_tokens = self.encoder.transformer(tokens)\n",
        "\n",
        "        # project encoder to decoder dimensions, if they are not equal.\n",
        "        decoder_tokens = self.enc_to_dec(encoded_tokens)\n",
        "\n",
        "        # decode tokens with decoder\n",
        "        decoded_tokens = self.decoder(decoder_tokens)\n",
        "\n",
        "        # project tokens to pixels\n",
        "        pred_pixel_values = self.to_pixels(decoded_tokens)\n",
        "\n",
        "        # calculate the loss with gt\n",
        "        gt_patches = self.to_patch(gt_img)\n",
        "        loss = F.mse_loss(pred_pixel_values, gt_patches)\n",
        "\n",
        "        return loss, patches, pred_pixel_values"
      ],
      "metadata": {
        "id": "jE8DR9r7YwIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate twice and load 2 different weight checkpoints \n",
        "\n",
        "v1 = ViT(\n",
        "    image_size = image_size,\n",
        "    patch_size = patch_size,\n",
        "    num_classes = 1000,\n",
        "    dim = encoder_dim,\n",
        "    depth = encoder_layers,\n",
        "    heads = encoder_heads,\n",
        "    mlp_dim = 2048\n",
        ")\n",
        "\n",
        "v2 = ViT(\n",
        "    image_size = image_size,\n",
        "    patch_size = patch_size,\n",
        "    num_classes = 1000,\n",
        "    dim = encoder_dim,\n",
        "    depth = encoder_layers,\n",
        "    heads = encoder_heads,\n",
        "    mlp_dim = 2048\n",
        ")\n",
        "\n",
        "# Binary Output \n",
        "binaryModel = ScribbleNet(\n",
        "    encoder = v1,\n",
        "    decoder_dim = encoder_dim,      \n",
        "    decoder_depth = encoder_layers,\n",
        "    decoder_heads = encoder_heads       \n",
        ")\n",
        "\n",
        "# Scribble Output \n",
        "scribbleModel = ScribbleNet(\n",
        "    encoder = v2,\n",
        "    decoder_dim = encoder_dim,      \n",
        "    decoder_depth = encoder_layers,\n",
        "    decoder_heads = encoder_heads       \n",
        ")\n",
        "\n",
        "# Sending model to the device..\n",
        "scribbleModel=scribbleModel.to(device)\n",
        "binaryModel=binaryModel.to(device)\n",
        "\n",
        "# Model Weight Loadings ...\n",
        "binaryModel.load_state_dict(torch.load(BMODEL, map_location=device),strict=False)\n",
        "scribbleModel.load_state_dict(torch.load(SMODEL, map_location=device),strict=False)\n"
      ],
      "metadata": {
        "id": "y7-IF6UPYynr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utils for output cleaning \n",
        "def preprocess(deg_img):\n",
        "    deg_img = (np.array(deg_img) /255).astype('float32')\n",
        "    # normalize data\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    out_deg_img = np.zeros([3, *deg_img.shape[:-1]])\n",
        "    for i in range(3):\n",
        "        out_deg_img[i] = (deg_img[:,:,i] - mean[i]) / std[i]\n",
        "    return out_deg_img\n",
        "\n",
        "def readFullImage(path,PDIM=256,DIM=256,OVERLAP=0.25):    \n",
        "    input_patches=[]\n",
        "    emp = EMPatches()\n",
        "    try:\n",
        "        img = cv2.imread(path)\n",
        "        img = preprocess(img)\n",
        "        img = np.transpose(img)\n",
        "        img_patches, indices = emp.extract_patches(img,patchsize=PDIM,overlap=OVERLAP)\n",
        "        for i,patch in enumerate(img_patches):\n",
        "            resized=[DIM,DIM]\n",
        "            if patch.shape[0]!= DIM or patch.shape[1]!= DIM : \n",
        "                resized=[patch.shape[0],patch.shape[1]]\n",
        "                patch = cv2.resize(patch,(DIM,DIM),interpolation = cv2.INTER_AREA)\n",
        "            patch = np.asarray(patch,dtype=np.float32)\n",
        "            patch =  np.transpose(patch) \n",
        "            patch= np.expand_dims(patch,axis=0)\n",
        "            sample={'img':patch,'resized':resized}\n",
        "            input_patches.append(sample)\n",
        "    except Exception as exp : \n",
        "        print('ImageReading Error ! :{}'.format(exp))\n",
        "        return None \n",
        "    return input_patches,indices\n",
        "\n",
        "\n",
        "\n",
        "def inferenceTestImage(scribbleModel,binaryModel,path,PDIM=256,DIM=256,OVERLAP=0.25,save=True):\n",
        "    emp = EMPatches()\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "    \n",
        "    if not os.path.exists(path):\n",
        "        print('Invalid File Path !')\n",
        "        sys.exit()\n",
        "    else:\n",
        "        res_patches , indices = readFullImage(path,PDIM,DIM,OVERLAP)\n",
        "        \n",
        "        scribble_output_patches=[]\n",
        "        binary_output_patches=[]\n",
        "\n",
        "        for i,sample in enumerate(res_patches):\n",
        "            p = sample['img']\n",
        "            target_shape = (sample['resized'][1],sample['resized'][0])\n",
        "\n",
        "            with torch.no_grad():\n",
        "                inputs =torch.from_numpy(p).to(device)\n",
        "\n",
        "                # Pass through SModel \n",
        "                _,_,spred_pixel_values = scribbleModel(inputs,inputs)\n",
        "\n",
        "                # Pass through BModel \n",
        "                _,_,bpred_pixel_values = binaryModel(inputs,inputs)\n",
        "\n",
        "                # Scribble Pixels \n",
        "                srec_patches = spred_pixel_values\n",
        "                brec_patches = bpred_pixel_values\n",
        "\n",
        "                soutput_image = rearrange(srec_patches, 'b (h w) (p1 p2 c) -> b c (h p1) (w p2)',p1 = patch_size, p2 = patch_size,  h=image_size[0]//patch_size)\n",
        "                boutput_image = rearrange(brec_patches, 'b (h w) (p1 p2 c) -> b c (h p1) (w p2)',p1 = patch_size, p2 = patch_size,  h=image_size[0]//patch_size)\n",
        "                \n",
        "                soutput_image = soutput_image.cpu().numpy().squeeze()\n",
        "                boutput_image = boutput_image.cpu().numpy().squeeze()\n",
        "\n",
        "                soutput_image =  np.transpose(soutput_image,(2, 1, 0))\n",
        "                boutput_image =  np.transpose(boutput_image,(2, 1, 0))\n",
        "\n",
        "                # Resizing to get desired output \n",
        "                boutput_image = cv2.resize(boutput_image,target_shape, interpolation = cv2.INTER_AREA)\n",
        "                soutput_image = cv2.resize(soutput_image,target_shape, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "                for ch in range(3):\n",
        "                    soutput_image[:,:,ch] = (soutput_image[:,:,ch] *std[ch]) + mean[ch]\n",
        "                    boutput_image[:,:,ch] = (boutput_image[:,:,ch] *std[ch]) + mean[ch]\n",
        "                \n",
        "\n",
        "                # Basic Thresholding \n",
        "                soutput_image[np.where(soutput_image>1)] = 1\n",
        "                soutput_image[np.where(soutput_image<0)] = 0\n",
        "\n",
        "                boutput_image[np.where(boutput_image>1)] = 1\n",
        "                boutput_image[np.where(boutput_image<0)] = 0\n",
        "\n",
        "\n",
        "                # binarize the predicted image taking 0.5 as threshold\n",
        "                soutput_image = (soutput_image>THRESHOLD)*1\n",
        "                boutput_image = (boutput_image>THRESHOLD)*1\n",
        "\n",
        "                # Append the net processed patch \n",
        "                scribble_output_patches.append(255*soutput_image)\n",
        "                binary_output_patches.append(255*boutput_image)\n",
        "                \n",
        "\n",
        "\n",
        "        assert len(res_patches) == len(scribble_output_patches)==len(binary_output_patches),\" Missing patches while processing !\"\n",
        "      \n",
        "        \n",
        "        # Restich the image \n",
        "        scribbleImage = emp.merge_patches(scribble_output_patches,indices)\n",
        "        binaryImage = emp.merge_patches(binary_output_patches,indices)\n",
        "\n",
        "        scribbleImage = np.transpose(scribbleImage,(1,0,2))\n",
        "        binaryImage = np.transpose(binaryImage,(1,0,2))\n",
        "\n",
        "        return scribbleImage,binaryImage"
      ],
      "metadata": {
        "id": "dEbYCQN_Y0J_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_polygons(polygons: list, eps) -> list:\n",
        "    \"\"\"\n",
        "    Split the touching and overlapping polygons.\n",
        "    :param polygons: The polygons to split.\n",
        "    :return polygons: The non-touching polygons.\n",
        "    \"\"\"\n",
        "    # Convert them into Shapely's polygon \n",
        "    polygons = [Polygon(poly) for poly in polygons if len(poly)>=4]\n",
        "\n",
        "    for comb in combinations(range(len(polygons)), 2):\n",
        "        poly1 = polygons[comb[0]]\n",
        "        poly2 = polygons[comb[1]]\n",
        "        # Skip invalid polygons as they cannot be compared.\n",
        "        if not poly1.is_valid or not poly2.is_valid:\n",
        "            continue\n",
        "        # If the two polygons intersect: first erode them, then check if they still intersect.\n",
        "        if poly1.intersects(poly2):\n",
        "            poly1 = poly1.buffer(-eps)\n",
        "            poly2 = poly2.buffer(-eps)\n",
        "            intersection = poly1.intersection(poly2)\n",
        "            # If they still intersect, remove the intersection from the biggest polygon.\n",
        "            if not intersection.is_empty:\n",
        "                if (\n",
        "                    isinstance(intersection, Polygon)\n",
        "                    and intersection.area < 0.2 * poly1.area\n",
        "                    and intersection.area < 0.2 * poly2.area\n",
        "                    or isinstance(intersection, MultiPolygon)\n",
        "                ):\n",
        "                    if poly1.area > poly2.area:\n",
        "                        polygons[comb[0]] = poly1.difference(intersection)\n",
        "                        polygons[comb[1]] = poly2.buffer(-eps)\n",
        "                    else:\n",
        "                        polygons[comb[1]] = poly2.difference(intersection)\n",
        "                        polygons[comb[0]] = poly1.buffer(-eps)\n",
        "                elif isinstance(intersection, LineString):\n",
        "                    polygons[comb[0]] = poly1.difference(intersection)\n",
        "                    polygons[comb[1]] = poly2.difference(intersection)\n",
        "        elif poly1.touches(poly2):\n",
        "            polygons[comb[0]] = poly1.buffer(-2 * eps)\n",
        "            polygons[comb[1]] = poly2.buffer(-2 * eps)\n",
        "    # Erode all polygons so that they don't touch when drawn over the label image.\n",
        "    polygons = [poly.buffer(-2 * eps) for poly in polygons]\n",
        "    return polygons\n",
        "\n",
        "def int_coords(x: np.array) -> np.array:\n",
        "  return np.array(x).round().astype(np.int32)\n",
        "\n",
        "def generateNewPolygons(image,polygons,eps=2,vis=True):\n",
        "  newpolys = split_polygons(polygons,eps = eps)\n",
        "  # Convert them to points \n",
        "  gdpolygons = []\n",
        "  for p in newpolys:\n",
        "    poly = int_coords(p.exterior.coords)\n",
        "    gdpolygons.append(poly.tolist())\n",
        "\n",
        "  if vis : \n",
        "    newCanvas = np.zeros(image.shape)\n",
        "    for element in gdpolygons : \n",
        "      npoly = np.asarray(element,dtype=np.int32).reshape((-1,1,2))\n",
        "      newCanvas  = cv2.fillPoly(newCanvas , [npoly], color=(255,255,255))\n",
        "  return gdpolygons,newCanvas      "
      ],
      "metadata": {
        "id": "jLkSeTDjo895"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x# Call the pipeline to be ready \n",
        "\n",
        "s,b = inferenceTestImage(scribbleModel,binaryModel,IMAGE_PATH,PDIM=256,DIM=256,OVERLAP=0.25,save=True)\n",
        "# _,b = inferenceTestImage(scribbleModel,binaryModel,IMAGE_PATH,PDIM=256,DIM=256,OVERLAP=0.50,save=True)\n",
        "print('Scribble Output : ')\n",
        "cv2_imshow(s)\n",
        "print('Binary Output : ')\n",
        "cv2_imshow(b)\n",
        "cv2.imwrite('bin_191.jpg',b)"
      ],
      "metadata": {
        "id": "9bi_klE0Y0j8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Utils \n",
        "def deformat(listofpoints):\n",
        "    # Input : [[[x1,y1],[[x2,y2]],[[x3,y3]]....]\n",
        "    # Output : [ [x1,y1], [x2,y2],[x3,y3]....]\n",
        "    output = [ pt[0].tolist() for pt in listofpoints ]\n",
        "    return output \n",
        "\n",
        "def oBox(c):\n",
        "  points = np.array(c)\n",
        "  # Fill the bbox \n",
        "  rect = cv2.minAreaRect(points)\n",
        "  box = cv2.boxPoints(rect)\n",
        "  box = np.int0(box)\n",
        "  return box \n",
        "\n",
        "# Supply the raw image here\n",
        "def cleanImageFindContours(patch,threshold = 0.10):\n",
        "  try:\n",
        "    patch = np.uint8(patch)\n",
        "    patch = cv2.cvtColor(patch,cv2.COLOR_BGR2GRAY)\n",
        "    contours, hierarchy = cv2.findContours(patch,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if len(contours)<1:\n",
        "      print('No contours in the raw image!')\n",
        "      return patch\n",
        "    # Else sort them \n",
        "    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x),reverse=True)\n",
        "    areaList = [cv2.contourArea(c) for c in cntsSorted]\n",
        "    maxArea = max(areaList)\n",
        "    sortedContours = [deformat(c) for c in cntsSorted if cv2.contourArea(c)>threshold*maxArea]\n",
        "    return sortedContours\n",
        "\n",
        "  except Exception as exp : \n",
        "    print('Error in figuring out the clean contours ')\n",
        "    return None "
      ],
      "metadata": {
        "id": "XOLXcH4dmXoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "csVTrjq6oZoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def firstProcess(s):\n",
        "  # Get the clean polygons first \n",
        "  contours = cleanImageFindContours(s.copy(),threshold = 0.05)\n",
        "  patch = np.uint8(s.copy())\n",
        "  print('Old Eroded Canvas')\n",
        "  newcanvas = np.zeros(s.shape)\n",
        "  newobboxs = []\n",
        "  for c in contours :\n",
        "    c = np.asarray(c)\n",
        "    box =  oBox(c)\n",
        "    newobboxs.append(box)\n",
        "    newcanvas = cv2.fillPoly(newcanvas,pts=[box],color=(255,255,255))\n",
        "  cv2_imshow(newcanvas)\n",
        "  # Send it to the canvas \n",
        "  polys,canv=generateNewPolygons(newcanvas,newobboxs,eps=2,vis=True)\n",
        "  print('NEW Canvas')\n",
        "  cv2_imshow(canv)\n",
        "  return canv,polys\n",
        "\n",
        "snew,polys = firstProcess(s)"
      ],
      "metadata": {
        "id": "zKl8zUI3nUkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Skeletonise \n",
        "\n",
        "def scribbleGeneration(img,box):\n",
        "    h,w,c = img.shape\n",
        "    canvas = np.zeros((h,w))\n",
        "    box = np.asarray(box,dtype=np.int32)\n",
        "    box = box.reshape(-1,1,2)\n",
        "    canvas = cv2.fillPoly(canvas,pts=np.int32([box]), color=(255,255,255))\n",
        "    skeleton = pcv.morphology.skeletonize(canvas)\n",
        "    pruned_skeleton, segmented_img, segment_objects = pcv.morphology.prune(skel_img=skeleton,size=100)\n",
        "    # cv2_imshow(pruned_skeleton)\n",
        "    scribble = np.asarray(segment_objects[0]).tolist()\n",
        "    return scribble \n",
        "\n"
      ],
      "metadata": {
        "id": "4OnDCSGKmQyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "nc = np.zeros(img.shape)\n",
        "scribbles=[]\n",
        "for i,pol in enumerate(polys):\n",
        "  s = scribbleGeneration(img,pol)\n",
        "  scribbles.append(s)"
      ],
      "metadata": {
        "id": "AW5c5S5rmQ3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parentCanvas = np.zeros(img.shape)\n",
        "for c in scribbles:\n",
        "  c = np.asarray(c)\n",
        "  parentCanvas = cv2.polylines(parentCanvas,[c],False,(255,255,255),3)\n",
        "cv2_imshow(parentCanvas)"
      ],
      "metadata": {
        "id": "Ntn2zFC1J6Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findClosePointsV2(p1,p2,dist):\n",
        "  hdist = np.abs(p1[1]-p2[1])**2\n",
        "  vdist = np.abs(p1[0]-p2[0])**2\n",
        "  pointDist = np.sqrt(hdist+vdist)\n",
        "  if pointDist<=dist :\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def extremePoints(c):\n",
        "    c = np.asarray(c).reshape(-1,1,2)\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    return extLeft,extRight\n",
        "\n",
        "def fuseScribbles(scribbles,patch,distanceThreshold=100):\n",
        "    # Collect all the startPoints , endPoints ( with their parent index )\n",
        "    endPointDict = []\n",
        "    startPointDict = []\n",
        "    for i in range(0,len(scribbles)):\n",
        "      # Grab the start and end points.\n",
        "      endPoint,startPoint = extremePoints(scribbles[i])\n",
        "      endPointDict.append(list(endPoint))\n",
        "      startPointDict.append(list(startPoint))\n",
        "    \n",
        "    # Draw the connecting scribbles on the patch.\n",
        "    gapCanvas = np.zeros(patch.shape)\n",
        "    for i in range(0,len(startPointDict)):\n",
        "      for j in range(0,len(endPointDict)):\n",
        "          if i!=j:\n",
        "            if j>i :\n",
        "              decision = findClosePointsV2(startPointDict[i],endPointDict[j],distanceThreshold)\n",
        "              if decision: \n",
        "                  gapCanvas = cv2.line(gapCanvas,startPointDict[i],endPointDict[j],color=(255,255,255),thickness=3)\n",
        "\n",
        "            else:\n",
        "              decision = findClosePointsV2(endPointDict[i],startPointDict[j],distanceThreshold)\n",
        "              if decision: \n",
        "                  gapCanvas = cv2.line(gapCanvas,endPointDict[i],startPointDict[j],color=(255,255,255),thickness=3)\n",
        "          else:\n",
        "            continue \n",
        "    \n",
        "    # Return this canvas \n",
        "    return gapCanvas"
      ],
      "metadata": {
        "id": "EuLwgx-umQ6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gapMap = fuseScribbles(scribbles,img)\n",
        "cv2_imshow(gapMap)"
      ],
      "metadata": {
        "id": "-3Ye4xTGKRWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netMap = cv2.bitwise_or(parentCanvas,gapMap)\n",
        "finalContours = cleanImageFindContours(netMap,threshold=0.1)\n",
        "# # Apply find contours on this one \n",
        "fcanvas = np.zeros(netMap.shape)\n",
        "for c in finalContours:\n",
        "  c = np.asarray(c)\n",
        "  fcanvas = cv2.polylines(fcanvas,[c],False,(255,255,255),5)\n",
        "\n",
        "cv2_imshow(fcanvas)"
      ],
      "metadata": {
        "id": "FLVuC9mAOdD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "New Additional Utils : V2 \n",
        "'''\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "def houghLinesProcessing(src,vis=False):\n",
        "\n",
        "    # Grayscale + Thresholding\n",
        "    src = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
        "    src[src > 127] = 255\n",
        "    src[src <= 127] = 0\n",
        "    \n",
        "    \n",
        "    dst = np.copy(src)\n",
        "    # Copy edges to the images that will display the results in BGR\n",
        "    cdst = cv.cvtColor(dst, cv.COLOR_GRAY2BGR)\n",
        "    cdstP = np.copy(cdst)\n",
        "\n",
        "    dst = np.uint8(dst)\n",
        "    lines = cv.HoughLines(dst, 1, np.pi / 180, 150, None, 0, 0)\n",
        "\n",
        "    if vis : \n",
        "        if lines is not None:\n",
        "            for i in range(0, len(lines)):\n",
        "                rho = lines[i][0][0]\n",
        "                theta = lines[i][0][1]\n",
        "                a = math.cos(theta)\n",
        "                b = math.sin(theta)\n",
        "                x0 = a * rho\n",
        "                y0 = b * rho\n",
        "                pt1 = (int(x0 + 1000*(-b)), int(y0 + 1000*(a)))\n",
        "                pt2 = (int(x0 - 1000*(-b)), int(y0 - 1000*(a)))\n",
        "                cv.line(cdst, pt1, pt2, (0,0,255), 3, cv.LINE_AA)\n",
        "\n",
        "    # DST MAP\n",
        "    linesP = cv.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10)\n",
        "\n",
        "    if linesP is not None:\n",
        "        for i in range(0, len(linesP)):\n",
        "            l = linesP[i][0]\n",
        "            cv.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv.LINE_AA)\n",
        "\n",
        "    return linesP,cdstP\n",
        "   \n",
        "class HoughBundler:     \n",
        "    def __init__(self,min_distance=5,min_angle=2):\n",
        "        self.min_distance = min_distance\n",
        "        self.min_angle = min_angle\n",
        "    \n",
        "    def get_orientation(self, line):\n",
        "        orientation = math.atan2(abs((line[3] - line[1])), abs((line[2] - line[0])))\n",
        "        return math.degrees(orientation)\n",
        "\n",
        "    def check_is_line_different(self, line_1, groups, min_distance_to_merge, min_angle_to_merge):\n",
        "        for group in groups:\n",
        "            for line_2 in group:\n",
        "                if self.get_distance(line_2, line_1) < min_distance_to_merge:\n",
        "                    orientation_1 = self.get_orientation(line_1)\n",
        "                    orientation_2 = self.get_orientation(line_2)\n",
        "                    if abs(orientation_1 - orientation_2) < min_angle_to_merge:\n",
        "                        group.append(line_1)\n",
        "                        return False\n",
        "        return True\n",
        "\n",
        "    def distance_point_to_line(self, point, line):\n",
        "        px, py = point\n",
        "        x1, y1, x2, y2 = line\n",
        "\n",
        "        def line_magnitude(x1, y1, x2, y2):\n",
        "            line_magnitude = math.sqrt(math.pow((x2 - x1), 2) + math.pow((y2 - y1), 2))\n",
        "            return line_magnitude\n",
        "\n",
        "        lmag = line_magnitude(x1, y1, x2, y2)\n",
        "        if lmag < 0.00000001:\n",
        "            distance_point_to_line = 9999\n",
        "            return distance_point_to_line\n",
        "\n",
        "        u1 = (((px - x1) * (x2 - x1)) + ((py - y1) * (y2 - y1)))\n",
        "        u = u1 / (lmag * lmag)\n",
        "\n",
        "        if (u < 0.00001) or (u > 1):\n",
        "            #// closest point does not fall within the line segment, take the shorter distance\n",
        "            #// to an endpoint\n",
        "            ix = line_magnitude(px, py, x1, y1)\n",
        "            iy = line_magnitude(px, py, x2, y2)\n",
        "            if ix > iy:\n",
        "                distance_point_to_line = iy\n",
        "            else:\n",
        "                distance_point_to_line = ix\n",
        "        else:\n",
        "            # Intersecting point is on the line, use the formula\n",
        "            ix = x1 + u * (x2 - x1)\n",
        "            iy = y1 + u * (y2 - y1)\n",
        "            distance_point_to_line = line_magnitude(px, py, ix, iy)\n",
        "\n",
        "        return distance_point_to_line\n",
        "\n",
        "    def get_distance(self, a_line, b_line):\n",
        "        dist1 = self.distance_point_to_line(a_line[:2], b_line)\n",
        "        dist2 = self.distance_point_to_line(a_line[2:], b_line)\n",
        "        dist3 = self.distance_point_to_line(b_line[:2], a_line)\n",
        "        dist4 = self.distance_point_to_line(b_line[2:], a_line)\n",
        "\n",
        "        return min(dist1, dist2, dist3, dist4)\n",
        "\n",
        "    def merge_lines_into_groups(self, lines):\n",
        "        groups = []  # all lines groups are here\n",
        "        # first line will create new group every time\n",
        "        groups.append([lines[0]])\n",
        "        # if line is different from existing gropus, create a new group\n",
        "        for line_new in lines[1:]:\n",
        "            if self.check_is_line_different(line_new, groups, self.min_distance, self.min_angle):\n",
        "                groups.append([line_new])\n",
        "\n",
        "        return groups\n",
        "\n",
        "    def merge_line_segments(self, lines):\n",
        "        orientation = self.get_orientation(lines[0])\n",
        "      \n",
        "        if(len(lines) == 1):\n",
        "            return np.block([[lines[0][:2], lines[0][2:]]])\n",
        "\n",
        "        points = []\n",
        "        for line in lines:\n",
        "            points.append(line[:2])\n",
        "            points.append(line[2:])\n",
        "        if 45 < orientation <= 90:\n",
        "            #sort by y\n",
        "            points = sorted(points, key=lambda point: point[1])\n",
        "        else:\n",
        "            #sort by x\n",
        "            points = sorted(points, key=lambda point: point[0])\n",
        "\n",
        "        return np.block([[points[0],points[-1]]])\n",
        "\n",
        "    def process_lines(self, lines):\n",
        "        lines_horizontal  = []\n",
        "        lines_vertical  = []\n",
        "  \n",
        "        for line_i in [l[0] for l in lines]:\n",
        "            orientation = self.get_orientation(line_i)\n",
        "            # if vertical\n",
        "            if 45 < orientation <= 90:\n",
        "                lines_vertical.append(line_i)\n",
        "            else:\n",
        "                lines_horizontal.append(line_i)\n",
        "\n",
        "        lines_vertical  = sorted(lines_vertical , key=lambda line: line[1])\n",
        "        lines_horizontal  = sorted(lines_horizontal , key=lambda line: line[0])\n",
        "        merged_lines_all = []\n",
        "\n",
        "        # for each cluster in vertical and horizantal lines leave only one line\n",
        "        for i in [lines_horizontal, lines_vertical]:\n",
        "            if len(i) > 0:\n",
        "                groups = self.merge_lines_into_groups(i)\n",
        "                merged_lines = []\n",
        "                for group in groups:\n",
        "                    merged_lines.append(self.merge_line_segments(group))\n",
        "                merged_lines_all.extend(merged_lines)\n",
        "                    \n",
        "        return np.asarray(merged_lines_all)"
      ],
      "metadata": {
        "id": "nPLqDMvCmQ8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Apply the global post processing - Hough Lines \n",
        "reImage = copy.deepcopy(parentCanvas)\n",
        "reImage = np.asarray(reImage)\n",
        "print('REIMAGE OLD : {}'.format(reImage.shape))\n",
        "res = np.transpose(reImage)\n",
        "print('REIMAGE NEW : {}'.format(res.shape))\n",
        "bundler = HoughBundler(min_distance=15,min_angle=5)\n"
      ],
      "metadata": {
        "id": "z77Fz2LTQVPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the global post processing - Hough Lines \n",
        "reImage = copy.deepcopy(fcanvas.astype(np.uint8))\n",
        "bundler = HoughBundler(min_distance=15,min_angle=5)\n",
        "linesP,hough_canvas=houghLinesProcessing(reImage,vis=False)\n",
        "filtered_lines = bundler.process_lines(linesP)\n",
        "\n",
        "# Draw them on canvas \n",
        "canvas = np.zeros(img.shape)\n",
        "for i in range(0,len(filtered_lines)):\n",
        "    l = filtered_lines[i][0]\n",
        "    canvas = cv.line(canvas,(l[0], l[1]), (l[2], l[3]), (255,255,255),6, cv.LINE_AA)\n"
      ],
      "metadata": {
        "id": "KjZMxBiVS8WK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(canvas)"
      ],
      "metadata": {
        "id": "GfhiDr49QVQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findClosePointsV2(p1,p2,dist):\n",
        "  hdist = np.abs(p1[1]-p2[1])\n",
        "  if hdist<=dist :\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def sort_contours(contoursList, x_axis_sort='LEFT_TO_RIGHT', y_axis_sort='TOP_TO_BOTTOM'):\n",
        "    # initialize the reverse flag\n",
        "    x_reverse = False\n",
        "    y_reverse = False\n",
        "    if x_axis_sort == 'RIGHT_TO_LEFT':\n",
        "        x_reverse = True\n",
        "    if y_axis_sort == 'BOTTOM_TO_TOP':\n",
        "        y_reverse = True\n",
        "    # Edit the contours \n",
        "    contours=[]\n",
        "    for c in contoursList :\n",
        "      c = np.asarray(c,dtype=np.int32).reshape(-1,2) \n",
        "      c = c.tolist()\n",
        "      contours.append(c)\n",
        "    boundingBoxes = [cv2.boundingRect(np.asarray(c)) for c in contours]\n",
        "    # sorting on x-axis \n",
        "    sortedByX = zip(*sorted(zip(contours, boundingBoxes),\n",
        "    key=lambda b:b[1][0], reverse=x_reverse))\n",
        "    # sorting on y-axis \n",
        "    (contours, boundingBoxes) = zip(*sorted(zip(*sortedByX),\n",
        "    key=lambda b:b[1][1], reverse=y_reverse))\n",
        "    # return the list of sorted contours and bounding boxes\n",
        "    return contours\n",
        "\n",
        "def fuseScribbles(scribbles,patch,distanceThreshold=20):\n",
        "    # Sort the scribbles \n",
        "    sortedScribbles = sort_contours(scribbles, x_axis_sort='RIGHT_TO_LEFT', y_axis_sort='TOP_TO_BOTTOM')\n",
        "    \n",
        "    # Collect all the startPoints , endPoints ( with their parent index )\n",
        "    endPointDict = []\n",
        "    startPointDict = []\n",
        "    for i in range(0,len(sortedScribbles)):\n",
        "      # Grab the start and end points.\n",
        "      endPoint,startPoint = extremePoints(sortedScribbles[i])\n",
        "      endPointDict.append(list(endPoint))\n",
        "      startPointDict.append(list(startPoint))\n",
        "    \n",
        "    # Draw the connecting scribbles on the patch.\n",
        "    gapCanvas = np.zeros(patch.shape)\n",
        "    for i in range(0,len(startPointDict)):\n",
        "      for j in range(0,len(endPointDict)):\n",
        "          if i!=j:\n",
        "            decision = findClosePointsV2(startPointDict[i],endPointDict[j],distanceThreshold)\n",
        "            if decision: \n",
        "              gapCanvas = cv2.line(gapCanvas,startPointDict[i],endPointDict[j],color=(255,255,255),thickness=3)\n",
        "            else:\n",
        "              continue \n",
        "    \n",
        "    # Return this canvas \n",
        "    return gapCanvas\n"
      ],
      "metadata": {
        "id": "SLh5uuZ8a7vK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patch = np.uint8(canvas)\n",
        "patch = cv2.cvtColor(patch,cv2.COLOR_BGR2GRAY)\n",
        "contours, hierarchy = cv2.findContours(patch,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "gcanvas = fuseScribbles(contours,patch,distanceThreshold=10)\n",
        "cv2_imshow(gcanvas)"
      ],
      "metadata": {
        "id": "2zSdQTnqcMKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gapCanvas = fuseScribbles(finscribbles,fcanvas,distanceThreshold=20)\n",
        "netMap = cv2.bitwise_or(gcanvas,patch)\n",
        "cv2_imshow(netMap)\n",
        "\n",
        "# src = netMap\n",
        "# # src = cv2.cvtColor(fcanvas,cv2.COLOR_BGR2GRAY)\n",
        "# src[src<100]=0\n",
        "# src[src>=100]=1\n",
        "# src = np.uint8(src)\n",
        "# scribbles = find_lines(src)\n",
        "\n",
        "# # For visualisation \n",
        "# scanvas = np.zeros(src.shape)\n",
        "# for c in scribbles:\n",
        "#   c = np.asarray(c)\n",
        "#   scanvas = cv2.polylines(scanvas,[c],False,(255,255,255),3)\n"
      ],
      "metadata": {
        "id": "hrZ-GPzTcDKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jTSdKpZlQViC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aFbak1lzQVkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P0xXIplMQVnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzj1dyiHmQ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9QIpbOamRBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IbWUv1oBmRD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Q9-qrZnmRGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ljwOzpGRmRJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# New Utils \n",
        "def deformat(listofpoints):\n",
        "    # Input : [[[x1,y1],[[x2,y2]],[[x3,y3]]....]\n",
        "    # Output : [ [x1,y1], [x2,y2],[x3,y3]....]\n",
        "    output = [ pt[0].tolist() for pt in listofpoints ]\n",
        "    return output \n",
        "\n",
        "# Sorting \n",
        "def sort_contours(contoursList, x_axis_sort='LEFT_TO_RIGHT', y_axis_sort='TOP_TO_BOTTOM'):\n",
        "    # initialize the reverse flag\n",
        "    x_reverse = False\n",
        "    y_reverse = False\n",
        "    if x_axis_sort == 'RIGHT_TO_LEFT':\n",
        "        x_reverse = True\n",
        "    if y_axis_sort == 'BOTTOM_TO_TOP':\n",
        "        y_reverse = True\n",
        "    # Edit the contours \n",
        "    contours=[]\n",
        "    for c in contoursList :\n",
        "      c = np.asarray(c,dtype=np.int32).reshape(-1,2) \n",
        "      c = c.tolist()\n",
        "      contours.append(c)\n",
        "    boundingBoxes = [cv2.boundingRect(np.asarray(c)) for c in contours]\n",
        "    # sorting on x-axis \n",
        "    sortedByX = zip(*sorted(zip(contours, boundingBoxes),\n",
        "    key=lambda b:b[1][0], reverse=x_reverse))\n",
        "    # sorting on y-axis \n",
        "    (contours, boundingBoxes) = zip(*sorted(zip(*sortedByX),\n",
        "    key=lambda b:b[1][1], reverse=y_reverse))\n",
        "    # return the list of sorted contours and bounding boxes\n",
        "    return contours\n",
        "\n",
        "# Supply the raw image here\n",
        "def cleanImageFindContours(patch,threshold = 0.10):\n",
        "  try:\n",
        "    patch = np.uint8(patch)\n",
        "    patch = cv2.cvtColor(patch,cv2.COLOR_BGR2GRAY)\n",
        "    contours, hierarchy = cv2.findContours(patch,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    if len(contours)<1:\n",
        "      print('No contours in the raw image!')\n",
        "      return patch\n",
        "    # Else sort them \n",
        "    cntsSorted = sorted(contours, key=lambda x: cv2.contourArea(x),reverse=True)\n",
        "    areaList = [cv2.contourArea(c) for c in cntsSorted]\n",
        "    maxArea = max(areaList)\n",
        "    sortedContours = [deformat(c) for c in cntsSorted if cv2.contourArea(c)>threshold*maxArea]\n",
        "    return sortedContours\n",
        "\n",
        "  except Exception as exp : \n",
        "    print('Error in figuring out the clean contours ')\n",
        "    return None \n",
        "  \n",
        "\n",
        "def deformatV2(listofpoints):\n",
        "    # Input : [[[x1,y1],[[x2,y2]],[[x3,y3]]....]\n",
        "    # Output : [ [x1,y1], [x2,y2],[x3,y3]....]\n",
        "    output = [ pt[0] for pt in listofpoints ]\n",
        "    return output \n",
        "\n",
        "\n",
        "def extremePoints(c):\n",
        "    c = np.asarray(c).reshape(-1,1,2)\n",
        "    extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "    extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "    return extLeft,extRight\n",
        "\n",
        "def find_lines(lines_mask,binaryThreshold=100):\n",
        "    \"\"\"\n",
        "    Finds the longest central line for each connected component in the given binary mask.\n",
        "\n",
        "    :param lines_mask: Binary mask of the detected line-areas\n",
        "    :return: a list of Opencv-style polygonal lines (each contour encoded as [N,1,2] elements where each tuple is (x,y) )\n",
        "    \"\"\"\n",
        "    \n",
        "    # lines_mask = cv2.cvtColor(lines_mask,cv2.COLOR_BGR2GRAY)\n",
        "    # lines_mask[lines_mask<binaryThreshold]=0\n",
        "    # lines_mask[lines_mask>=binaryThreshold]=1\n",
        "    # lines_mask = np.uint8(lines_mask)\n",
        "\n",
        "    # Make sure one-pixel wide 8-connected mask\n",
        "    lines_mask = skeletonize(lines_mask)\n",
        "\n",
        "    class MakeLineMCP(MCP_Connect):\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            super().__init__(*args, **kwargs)\n",
        "            self.connections = dict()\n",
        "            self.scores = defaultdict(lambda: np.inf)\n",
        "\n",
        "        def create_connection(self, id1, id2, pos1, pos2, cost1, cost2):\n",
        "            k = (min(id1, id2), max(id1, id2))\n",
        "            s = cost1 + cost2\n",
        "            if self.scores[k] > s:\n",
        "                self.connections[k] = (pos1, pos2, s)\n",
        "                self.scores[k] = s\n",
        "\n",
        "        def get_connections(self, subsample=5):\n",
        "            results = dict()\n",
        "            for k, (pos1, pos2, s) in self.connections.items():\n",
        "                path = np.concatenate([self.traceback(pos1), self.traceback(pos2)[::-1]])\n",
        "                results[k] = path[::subsample]\n",
        "            return results\n",
        "\n",
        "        def goal_reached(self, int_index, float_cumcost):\n",
        "            if float_cumcost > 0:\n",
        "                return 2\n",
        "            else:\n",
        "                return 0\n",
        "\n",
        "    if np.sum(lines_mask) == 0:\n",
        "        return []\n",
        "    # Find extremities points\n",
        "    end_points_candidates = np.stack(np.where((convolve2d(lines_mask, np.ones((3, 3)), mode='same') == 2) & lines_mask)).T\n",
        "    connected_components = skimage_label(lines_mask, connectivity=2)\n",
        "    # Group endpoint by connected components and keep only the two points furthest away\n",
        "    d = defaultdict(list)\n",
        "    for pt in end_points_candidates:\n",
        "        d[connected_components[pt[0], pt[1]]].append(pt)\n",
        "    end_points = []\n",
        "    for pts in d.values():\n",
        "        d = euclidean_distances(np.stack(pts), np.stack(pts))\n",
        "        i, j = np.unravel_index(d.argmax(), d.shape)\n",
        "        end_points.append(pts[i])\n",
        "        end_points.append(pts[j])\n",
        "    end_points = np.stack(end_points)\n",
        "\n",
        "    mcp = MakeLineMCP(~lines_mask)\n",
        "    mcp.find_costs(end_points)\n",
        "    connections = mcp.get_connections()\n",
        "    if not np.all(np.array(sorted([i for k in connections.keys() for i in k])) == np.arange(len(end_points))):\n",
        "        print('Warning : find_lines seems weird')\n",
        "    return [c[:, None, ::-1] for c in connections.values()]\n",
        "\n",
        "def sort_contours(contoursList, x_axis_sort='LEFT_TO_RIGHT', y_axis_sort='TOP_TO_BOTTOM'):\n",
        "    # initialize the reverse flag\n",
        "    x_reverse = False\n",
        "    y_reverse = False\n",
        "    if x_axis_sort == 'RIGHT_TO_LEFT':\n",
        "        x_reverse = True\n",
        "    if y_axis_sort == 'BOTTOM_TO_TOP':\n",
        "        y_reverse = True\n",
        "    # Edit the contours \n",
        "    contours=[]\n",
        "    for c in contoursList :\n",
        "      c = np.asarray(c,dtype=np.int32).reshape(-1,2) \n",
        "      c = c.tolist()\n",
        "      contours.append(c)\n",
        "    boundingBoxes = [cv2.boundingRect(np.asarray(c)) for c in contours]\n",
        "    # sorting on x-axis \n",
        "    sortedByX = zip(*sorted(zip(contours, boundingBoxes),\n",
        "    key=lambda b:b[1][0], reverse=x_reverse))\n",
        "    # sorting on y-axis \n",
        "    (contours, boundingBoxes) = zip(*sorted(zip(*sortedByX),\n",
        "    key=lambda b:b[1][1], reverse=y_reverse))\n",
        "    # return the list of sorted contours and bounding boxes\n",
        "    return contours\n",
        "    \n",
        "def imageCombiner(imgs):\n",
        "  imgs_comb = np.hstack([i for i in imgs])\n",
        "  return imgs_comb\n",
        "\n"
      ],
      "metadata": {
        "id": "oLQadqvuY2G6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6zatxDDeao9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findClosePointsV2(p1,p2,dist):\n",
        "  hdist = np.abs(p1[1]-p2[1])\n",
        "  if hdist<=dist :\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def fuseScribbles(scribbles,patch,distanceThreshold=20):\n",
        "    # Sort the scribbles \n",
        "    sortedScribbles = sort_contours(scribbles, x_axis_sort='RIGHT_TO_LEFT', y_axis_sort='TOP_TO_BOTTOM')\n",
        "    \n",
        "    # Collect all the startPoints , endPoints ( with their parent index )\n",
        "    endPointDict = []\n",
        "    startPointDict = []\n",
        "    for i in range(0,len(sortedScribbles)):\n",
        "      # Grab the start and end points.\n",
        "      endPoint,startPoint = extremePoints(sortedScribbles[i])\n",
        "      endPointDict.append(list(endPoint))\n",
        "      startPointDict.append(list(startPoint))\n",
        "    \n",
        "    # Draw the connecting scribbles on the patch.\n",
        "    gapCanvas = np.zeros(patch.shape)\n",
        "    for i in range(0,len(startPointDict)):\n",
        "      for j in range(0,len(endPointDict)):\n",
        "          if i!=j:\n",
        "            decision = findClosePointsV2(startPointDict[i],endPointDict[j],distanceThreshold)\n",
        "            if decision: \n",
        "              gapCanvas = cv2.line(gapCanvas,startPointDict[i],endPointDict[j],color=(255,255,255),thickness=3)\n",
        "            else:\n",
        "              continue \n",
        "    \n",
        "    # Return this canvas \n",
        "    return gapCanvas\n",
        "\n",
        "\n",
        "def localPatchProcessing(patch,distThreshold=20):\n",
        "  try:\n",
        "    # Apply Set of Erosion + Dilation to solve it \n",
        "    rectkernel = np.ones((1,15),np.uint8)\n",
        "    erodeKernel =  np.ones((3,3),np.uint8)\n",
        "\n",
        "    rawImage = copy.deepcopy(patch)\n",
        "\n",
        "    rawImage = cv2.erode(rawImage,erodeKernel,iterations=2)\n",
        "    rawImage = cv2.dilate(rawImage,rectkernel,iterations=6)\n",
        "  \n",
        "    # Cleaning it up a bit \n",
        "    try:\n",
        "      finalContours = cleanImageFindContours(rawImage,threshold=0.1)\n",
        "      assert len(finalContours)> 1 , 'No white patches !'\n",
        "    except Exception as exp :\n",
        "      return None\n",
        "\n",
        "    # Plot all the filterd contours on canvs\n",
        "    contourList = [] \n",
        "    finalCanvas = np.zeros((rawImage.shape[0],rawImage.shape[1]))\n",
        "    for cnew in finalContours :\n",
        "        contourList.append(cnew)\n",
        "        points = np.array(cnew)\n",
        "        # Fill the bbox \n",
        "        rect = cv2.minAreaRect(points)\n",
        "        box = cv2.boxPoints(rect)\n",
        "        box = np.int0(box)\n",
        "        # Draw on the patch \n",
        "        # cv2.drawContours(im,[box],0,(0,0,255),2)\n",
        "        finalCanvas = cv2.fillPoly(finalCanvas,pts=[box],color=(255,255,255))\n",
        "        \n",
        "    src = finalCanvas\n",
        "    src[src<100]=0\n",
        "    src[src>=100]=1\n",
        "    src = np.uint8(src)\n",
        "    scribbles = find_lines(src)\n",
        "    \n",
        "\n",
        "    # Parent Canvas \n",
        "    parentCanvas = np.zeros(rawImage.shape)\n",
        "    for c in  scribbles:\n",
        "      c = np.asarray(c)\n",
        "      parentCanvas = cv2.polylines(parentCanvas,[c],False,(255,255,255),3)\n",
        "\n",
        "\n",
        "\n",
        "    gapCanvas = fuseScribbles(scribbles,parentCanvas,distanceThreshold=20)\n",
        "    netMap = cv2.bitwise_or(parentCanvas,gapCanvas)\n",
        "    # print('NETMAP : ')\n",
        "    # cv2_imshow(netMap)\n",
        "\n",
        "    # # Apply find contours again \n",
        "    finalContours = cleanImageFindContours(netMap,threshold=0.1)\n",
        "\n",
        "    # # Apply find contours on this one \n",
        "    fcanvas = np.zeros(netMap.shape)\n",
        "    for c in finalContours:\n",
        "      c = np.asarray(c)\n",
        "      fcanvas = cv2.polylines(fcanvas,[c],False,(255,255,255),5)\n",
        "    \n",
        "    # Final set of scribbles\n",
        "    src = fcanvas[:,:,0]\n",
        "    # src = cv2.cvtColor(fcanvas,cv2.COLOR_BGR2GRAY)\n",
        "    src[src<100]=0\n",
        "    src[src>=100]=1\n",
        "    src = np.uint8(src)\n",
        "    finscribbles = find_lines(src)\n",
        "\n",
        "    return finscribbles\n",
        "\n",
        "  except Exception as exp :\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def globalPostProcessing(localsmap,distanceThreshold=10):\n",
        "  # Apply Horizontal Erosion with thickness \n",
        "  clean_image = localsmap.copy()\n",
        "  rectkernel = np.ones((3,11),np.uint8)\n",
        "\n",
        "  rawImage = copy.deepcopy(clean_image)\n",
        "  rawImage = cv2.dilate(rawImage,rectkernel,iterations=7)\n",
        "\n",
        "  # Detect the scribbles now and apply them again \n",
        "  # Final set of scribbles\n",
        "  src = rawImage[:,:,0]\n",
        "  # src = cv2.cvtColor(fcanvas,cv2.COLOR_BGR2GRAY)\n",
        "  src[src<100]=0\n",
        "  src[src>=100]=1\n",
        "  src = np.uint8(src)\n",
        "\n",
        "  # First set of scribbles ( better joined )\n",
        "  finscribbles = find_lines(src)\n",
        "\n",
        "  fcanvas = np.zeros(src.shape)\n",
        "  for c in finscribbles:\n",
        "    c = np.asarray(c)\n",
        "    fcanvas = cv2.polylines(fcanvas,[c],False,(255,255,255),3)\n",
        "  # cv2_imshow(fcanvas)\n",
        "\n",
        "  # Fuse the remaining scribbles \n",
        "  gapCanvas = fuseScribbles(finscribbles,fcanvas,distanceThreshold=20)\n",
        "  netMap = cv2.bitwise_or(fcanvas,gapCanvas)\n",
        "  # cv2_imshow(netMap)\n",
        "\n",
        "  src = netMap\n",
        "  # src = cv2.cvtColor(fcanvas,cv2.COLOR_BGR2GRAY)\n",
        "  src[src<100]=0\n",
        "  src[src>=100]=1\n",
        "  src = np.uint8(src)\n",
        "  scribbles = find_lines(src)\n",
        "\n",
        "  # For visualisation \n",
        "  scanvas = np.zeros(src.shape)\n",
        "  for c in scribbles:\n",
        "    c = np.asarray(c)\n",
        "    scanvas = cv2.polylines(scanvas,[c],False,(255,255,255),3)\n",
        "  \n",
        "  return scribbles,scanvas\n"
      ],
      "metadata": {
        "id": "jjz9nTszY4Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gluePipeline(smap,PDIM=512,OVERLAP=0.25):\n",
        "  simg = copy.deepcopy(smap)\n",
        "  emp = EMPatches()\n",
        "  simg_patches, indices = emp.extract_patches(simg,patchsize=PDIM,overlap=OVERLAP)\n",
        "  # Patchified Processing \n",
        "  clean_patches = []\n",
        "  for i,sp in enumerate(simg_patches):\n",
        "    pscribbles = localPatchProcessing(patch=sp)\n",
        "    canvas = np.zeros(sp.shape)\n",
        "    if pscribbles is not None :\n",
        "      for cnew in pscribbles:\n",
        "        canvas = cv2.polylines(canvas,[cnew],False,(255,255,255),3)\n",
        "    clean_patches.append(canvas)\n",
        "  # Merge back into clean canvas mode.\n",
        "  clean_image = emp.merge_patches(clean_patches,indices)\n",
        "  # Global Post Processing \n",
        "  scribbles,ncanvas = globalPostProcessing(localsmap=clean_image.copy(),distanceThreshold=10)   \n",
        "  return scribbles,ncanvas\n"
      ],
      "metadata": {
        "id": "UfX0hOycY7N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scr,scanvas = gluePipeline(s,PDIM=512,OVERLAP=0.25)\n",
        "cv2_imshow(scanvas)"
      ],
      "metadata": {
        "id": "50HLZt1HY-oB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}